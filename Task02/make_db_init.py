#!/usr/bin/env python3
import os
import csv
import sqlite3
from pathlib import Path


def detect_delimiter(file_path):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –≤ —Ñ–∞–π–ª–µ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        first_line = f.readline()
        if '\t' in first_line:
            return '\t'
        elif '|' in first_line:
            return '|'
        elif ',' in first_line:
            return ','
        else:
            return '\t'


def get_table_structure(table_name):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º"""
    structures = {
        'movies': [
            ('id', 'INTEGER PRIMARY KEY AUTOINCREMENT'),
            ('title', 'TEXT'),
            ('year', 'INTEGER'),
            ('genres', 'TEXT')
        ],
        'ratings': [
            ('id', 'INTEGER PRIMARY KEY AUTOINCREMENT'),
            ('user_id', 'INTEGER'),
            ('movie_id', 'INTEGER'),
            ('rating', 'REAL'),
            ('timestamp', 'INTEGER')
        ],
        'tags': [
            ('id', 'INTEGER PRIMARY KEY AUTOINCREMENT'),
            ('user_id', 'INTEGER'),
            ('movie_id', 'INTEGER'),
            ('tag', 'TEXT'),
            ('timestamp', 'INTEGER')
        ],
        'users': [
            ('id', 'INTEGER PRIMARY KEY AUTOINCREMENT'),
            ('name', 'TEXT'),
            ('email', 'TEXT'),
            ('gender', 'TEXT'),
            ('register_date', 'TEXT'),
            ('occupation', 'TEXT')
        ]
    }
    return structures.get(table_name)


def map_file_to_table(file_path, table_name):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª —Å —Ç–∞–±–ª–∏—Ü–µ–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫"""
    # –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    mappings = {
        'movies.csv': {
            'table': 'movies',
            'mapping': {'title': 0, 'year': 1, 'genres': 2}
        },
        'ratings.csv': {
            'table': 'ratings',
            'mapping': {'user_id': 0, 'movie_id': 1, 'rating': 2, 'timestamp': 3}
        },
        'tags.csv': {
            'table': 'tags',
            'mapping': {'user_id': 0, 'movie_id': 1, 'tag': 2, 'timestamp': 3}
        },
        'users.txt': {
            'table': 'users',
            'mapping': {'name': 0, 'email': 1, 'gender': 2, 'register_date': 3, 'occupation': 4}
        }
    }

    filename = file_path.name
    if filename in mappings:
        return mappings[filename]

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
    return {'table': table_name, 'mapping': {}}


def read_headers_and_sample(file_path, delimiter):
    """–ß–∏—Ç–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫
        first_line = f.readline().strip()
        headers = [header.strip() for header in first_line.split(delimiter)]

        # –ß–∏—Ç–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö
        sample_data = []
        for _ in range(5):
            line = f.readline().strip()
            if line:
                sample_data.append(line.split(delimiter))

        return headers, sample_data


def generate_create_table(table_name):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –∫–æ–º–∞–Ω–¥—ã CREATE TABLE"""
    structure = get_table_structure(table_name)
    if not structure:
        return None

    sql = f"CREATE TABLE {table_name} (\n"
    columns = []
    for column_name, column_type in structure:
        columns.append(f"    {column_name} {column_type}")

    sql += ",\n".join(columns)
    sql += "\n);"
    return sql


def generate_insert_statements(table_name, file_path, mapping, delimiter):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –∫–æ–º–∞–Ω–¥ INSERT"""
    inserts = []
    table_structure = get_table_structure(table_name)
    if not table_structure:
        return inserts

    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f, delimiter=delimiter)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        next(reader, None)

        for row in reader:
            if row and any(cell.strip() for cell in row):  # –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                db_columns = []
                db_values = []

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∫–æ–ª–æ–Ω–∫—É —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ç–∞–±–ª–∏—Ü—ã
                for db_column, db_type in table_structure:
                    if db_column == 'id':
                        continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º id - –æ–Ω –∞–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω—ã–π

                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ
                    col_index = mapping.get(db_column, None)

                    if col_index is not None and col_index < len(row):
                        value = row[col_index].strip()
                    else:
                        value = ''

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è SQL
                    if not value:
                        db_values.append('NULL')
                    elif 'INTEGER' in db_type:
                        try:
                            db_values.append(str(int(float(value))))  # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ integer
                        except (ValueError, TypeError):
                            db_values.append('NULL')
                    elif 'REAL' in db_type:
                        try:
                            db_values.append(str(float(value)))
                        except (ValueError, TypeError):
                            db_values.append('NULL')
                    else:
                        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                        escaped_value = value.replace("'", "''")
                        db_values.append(f"'{escaped_value}'")

                    db_columns.append(db_column)

                if db_columns:
                    sql = f"INSERT INTO {table_name} ({', '.join(db_columns)}) VALUES ({', '.join(db_values)});"
                    inserts.append(sql)

    return inserts


def main():
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ dataset
    dataset_path = Path('dataset')
    if not dataset_path.exists():
        print("–û—à–∏–±–∫–∞: –∫–∞—Ç–∞–ª–æ–≥ 'dataset' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ dataset
    text_files = list(dataset_path.glob('*.txt')) + list(dataset_path.glob('*.csv'))

    if not text_files:
        print("–û—à–∏–±–∫–∞: –≤ –∫–∞—Ç–∞–ª–æ–≥–µ 'dataset' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã .txt –∏–ª–∏ .csv!")
        return

    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(text_files)}")
    for file in text_files:
        print(f"  - {file.name}")

    # –°–æ–∑–¥–∞–µ–º SQL —Å–∫—Ä–∏–ø—Ç
    sql_script = []
    sql_script.append("-- SQL Script generated by ETL process")
    sql_script.append("BEGIN TRANSACTION;")
    sql_script.append("")

    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã (—Ç–æ–ª—å–∫–æ —Ç—Ä–µ–±—É–µ–º—ã–µ)
    sql_script.append("-- Drop existing tables")
    required_tables = ['movies', 'ratings', 'tags', 'users']
    for table in required_tables:
        sql_script.append(f"DROP TABLE IF EXISTS {table};")
    sql_script.append("")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
    target_files = {
        'movies.csv': 'movies',
        'ratings.csv': 'ratings',
        'tags.csv': 'tags',
        'users.txt': 'users'
    }

    processed_count = 0

    for file_path in text_files:
        filename = file_path.name

        if filename in target_files:
            table_name = target_files[filename]
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {filename} -> —Ç–∞–±–ª–∏—Ü–∞: {table_name}")

            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                delimiter = detect_delimiter(file_path)

                # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è —Ñ–∞–π–ª–∞
                mapping_info = map_file_to_table(file_path, table_name)
                mapping = mapping_info['mapping']

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º CREATE TABLE
                create_sql = generate_create_table(table_name)
                if create_sql:
                    sql_script.append(f"-- Create table {table_name}")
                    sql_script.append(create_sql)
                    sql_script.append("")

                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º INSERT statements
                    sql_script.append(f"-- Insert data into {table_name}")
                    inserts = generate_insert_statements(table_name, file_path, mapping, delimiter)
                    sql_script.extend(inserts)
                    sql_script.append("")

                    print(f"  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(inserts)}")
                    processed_count += 1
                else:
                    print(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É {table_name}")

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename}: {str(e)}")
                continue
        else:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª: {filename} (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Ü–µ–ª–µ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü)")

    sql_script.append("COMMIT;")

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º SQL —Å–∫—Ä–∏–ø—Ç –≤ —Ñ–∞–π–ª
    with open('db_init.sql', 'w', encoding='utf-8', newline='\n') as f:
        f.write('\n'.join(sql_script))

    print(f"\n‚úÖ SQL —Å–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω: db_init.sql")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: {processed_count}")
    print(f"üìù –í—Å–µ–≥–æ –∫–æ–º–∞–Ω–¥: {len(sql_script)}")


if __name__ == "__main__":
    main()